#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <pthread.h>
#include <ctype.h>

#define MAX_WORD_LEN 50
#define HASH_SIZE 1000
#define MAX_THREADS 4

typedef struct WordNode {
    char word[MAX_WORD_LEN];
    int count;
    struct WordNode *next;
} WordNode;

typedef struct {
    FILE *file;
    long start;
    long end;
    WordNode *hash_table[HASH_SIZE];
} ThreadData;

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

// Hash function for words
unsigned int hash(const char *word) {
    unsigned int hash = 0;
    while (*word) {
        hash = (hash * 31) + *word++;
    }
    return hash % HASH_SIZE;
}

// Insert/update word frequency in hash table
void insert_word(WordNode *hash_table[], const char *word) {
    unsigned int index = hash(word);
    
    WordNode *node = hash_table[index];
    while (node) {
        if (strcmp(node->word, word) == 0) {
            node->count++;
            return;
        }
        node = node->next;
    }

    // Create new node
    WordNode *new_node = (WordNode *)malloc(sizeof(WordNode));
    strcpy(new_node->word, word);
    new_node->count = 1;
    new_node->next = hash_table[index];
    hash_table[index] = new_node;
}

// Reads next word from file
int get_next_word(FILE *file, char *buffer) {
    int c, i = 0;
    
    while ((c = fgetc(file)) != EOF) {
        if (isalnum(c)) {
            buffer[i++] = tolower(c);
        } else if (i > 0) {
            buffer[i] = '\0';
            return 1;
        }
    }
    
    if (i > 0) {
        buffer[i] = '\0';
        return 1;
    }
    
    return 0;
}

// Thread function to process a file segment
void *process_segment(void *arg) {
    ThreadData *data = (ThreadData *)arg;
    fseek(data->file, data->start, SEEK_SET);
    
    char word[MAX_WORD_LEN];
    long pos = data->start;
    
    while (pos < data->end && get_next_word(data->file, word)) {
        insert_word(data->hash_table, word);
        pos = ftell(data->file);
    }
    
    return NULL;
}

// Merge thread hash tables into a global hash table
void merge_results(WordNode *global_table[], WordNode *thread_table[]) {
    for (int i = 0; i < HASH_SIZE; i++) {
        WordNode *node = thread_table[i];
        while (node) {
            pthread_mutex_lock(&mutex);
            insert_word(global_table, node->word);
            pthread_mutex_unlock(&mutex);
            node = node->next;
        }
    }
}

// Print word frequencies
void print_word_frequencies(WordNode *hash_table[]) {
    for (int i = 0; i < HASH_SIZE; i++) {
        WordNode *node = hash_table[i];
        while (node) {
            printf("%s: %d\n", node->word, node->count);
            node = node->next;
        }
    }
}

// Free hash table memory
void free_hash_table(WordNode *hash_table[]) {
    for (int i = 0; i < HASH_SIZE; i++) {
        WordNode *node = hash_table[i];
        while (node) {
            WordNode *temp = node;
            node = node->next;
            free(temp);
        }
    }
}

int main(int argc, char *argv[]) {
    if (argc != 3) {
        fprintf(stderr, "Usage: %s <filename> <num_threads>\n", argv[0]);
        return 1;
    }

    char *filename = argv[1];
    int num_threads = atoi(argv[2]);
    if (num_threads <= 0 || num_threads > MAX_THREADS) {
        fprintf(stderr, "Invalid number of threads. Using %d threads.\n", MAX_THREADS);
        num_threads = MAX_THREADS;
    }

    FILE *file = fopen(filename, "r");
    if (!file) {
        perror("Error opening file");
        return 1;
    }

    fseek(file, 0, SEEK_END);
    long file_size = ftell(file);
    long segment_size = file_size / num_threads;
    rewind(file);

    pthread_t threads[num_threads];
    ThreadData thread_data[num_threads];
    WordNode *global_table[HASH_SIZE] = {NULL};

    for (int i = 0; i < num_threads; i++) {
        thread_data[i].file = fopen(filename, "r");
        thread_data[i].start = i * segment_size;
        thread_data[i].end = (i == num_threads - 1) ? file_size : (i + 1) * segment_size;
        memset(thread_data[i].hash_table, 0, sizeof(thread_data[i].hash_table));

        pthread_create(&threads[i], NULL, process_segment, &thread_data[i]);
    }

    for (int i = 0; i < num_threads; i++) {
        pthread_join(threads[i], NULL);
        merge_results(global_table, thread_data[i].hash_table);
        free_hash_table(thread_data[i].hash_table);
        fclose(thread_data[i].file);
    }

    print_word_frequencies(global_table);
    free_hash_table(global_table);
    fclose(file);

    return 0;
}
